#!/usr/bin/env node

/**
 * TapTalk íŠœí„° ì¸ì‚¬ë§ ìŒì„± ìƒì„± ìŠ¤í¬ë¦½íŠ¸
 *
 * ì‚¬ìš©ë²•: node scripts/generate-greetings.mjs
 *
 * ElevenLabs: Emma, James, Alina, Henly (ì•±ê³¼ ë™ì¼í•œ í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ)
 * OpenAI TTS: Charlotte, Oliver
 *
 * ì¶œë ¥: public/audio/greetings/{name}-greeting.mp3
 */

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import https from 'https';

const __dirname = path.dirname(fileURLToPath(import.meta.url));
const OUTPUT_DIR = path.join(__dirname, '..', 'public', 'audio', 'greetings');

// API Keys
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// ElevenLabs Voice IDs (ì•±ê³¼ ë™ì¼)
const ELEVENLABS_VOICE_MAP = {
  shimmer: 'EXAVITQu4vr4xnSDxMaL', // Emma
  echo: 'pNInz6obpgDQGcFmaJgB',    // James
  nova: 'jBpfuIE2acCO8z3wKNLl',     // Alina (kid)
  alloy: 'TX3LPaxmHKxFdv7VOQHJ',   // Henly (kid)
};

// ElevenLabs ì„ í˜¸ ìŒì„± (ì•±ê³¼ ë™ì¼í•œ í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ)
const ELEVENLABS_PREFERRED = new Set(['shimmer', 'echo', 'nova', 'alloy']);
const KID_VOICES = new Set(['nova', 'alloy']);

// íŠœí„°ë³„ ì¸ì‚¬ë§ (ìºë¦­í„° ì„±ê²© ë°˜ì˜, 5~8ì´ˆ ë¶„ëŸ‰)
const GREETINGS = [
  {
    name: 'emma',
    voice: 'shimmer',
    text: "Hey! I'm Emma! Oh my gosh, I'm so excited to practice English with you. We're gonna have so much fun, trust me!",
  },
  {
    name: 'james',
    voice: 'echo',
    text: "Yo, what's up! I'm James. We're just gonna hang out, have some chill conversations, no pressure at all. Let's do this!",
  },
  {
    name: 'charlotte',
    voice: 'fable',
    text: "Hello! I'm Charlotte. Lovely to meet you! We'll have a proper chat and I promise it won't be boring. Shall we get started?",
  },
  {
    name: 'oliver',
    voice: 'onyx',
    text: "Right then, I'm Oliver. Nice to meet you! We'll keep things casual, no fuss. Let's just have a good chat, yeah?",
  },
  {
    name: 'alina',
    voice: 'nova',
    text: "Hi hi! I'm Alina! This is gonna be so fun! I love talking and making new friends. Let's play and learn together!",
  },
  {
    name: 'henly',
    voice: 'alloy',
    text: "Hey! I'm Henly! Dude, talking in English is awesome! Let's be friends and have a super cool time together!",
  },
];

// ElevenLabs TTS
async function generateWithElevenLabs(text, voice) {
  const voiceId = ELEVENLABS_VOICE_MAP[voice];
  const isKid = KID_VOICES.has(voice);

  const voiceSettings = isKid
    ? { stability: 0.75, similarity_boost: 0.6, style: 0.3, use_speaker_boost: true }
    : { stability: 0.5, similarity_boost: 0.75, style: 0.5, use_speaker_boost: true };

  const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
    method: 'POST',
    headers: {
      'Accept': 'audio/mpeg',
      'Content-Type': 'application/json',
      'xi-api-key': ELEVENLABS_API_KEY,
    },
    body: JSON.stringify({
      text,
      model_id: 'eleven_turbo_v2_5',
      voice_settings: voiceSettings,
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`ElevenLabs error ${response.status}: ${errorText}`);
  }

  return Buffer.from(await response.arrayBuffer());
}

// OpenAI TTS
async function generateWithOpenAI(text, voice) {
  const response = await fetch('https://api.openai.com/v1/audio/speech', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${OPENAI_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'tts-1',
      voice,
      input: text,
      speed: 1.0,
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`OpenAI TTS error ${response.status}: ${errorText}`);
  }

  return Buffer.from(await response.arrayBuffer());
}

async function main() {
  // ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
  fs.mkdirSync(OUTPUT_DIR, { recursive: true });

  console.log('ğŸ¤ TapTalk íŠœí„° ì¸ì‚¬ë§ ìŒì„± ìƒì„± ì‹œì‘\n');
  console.log(`ğŸ“‚ ì¶œë ¥: ${OUTPUT_DIR}\n`);

  if (!ELEVENLABS_API_KEY) {
    console.warn('âš ï¸  ELEVENLABS_API_KEY ì—†ìŒ â€” ì „ë¶€ OpenAIë¡œ ìƒì„±í•©ë‹ˆë‹¤\n');
  }
  if (!OPENAI_API_KEY) {
    console.error('âŒ OPENAI_API_KEY í•„ìˆ˜!');
    process.exit(1);
  }

  for (const tutor of GREETINGS) {
    const useElevenLabs = ELEVENLABS_API_KEY && ELEVENLABS_PREFERRED.has(tutor.voice);
    const provider = useElevenLabs ? 'ElevenLabs' : 'OpenAI';

    console.log(`ğŸ”Š ${tutor.name} (${provider}, voice: ${tutor.voice})`);
    console.log(`   "${tutor.text}"`);

    try {
      let audioBuffer;
      if (useElevenLabs) {
        try {
          audioBuffer = await generateWithElevenLabs(tutor.text, tutor.voice);
        } catch (err) {
          console.warn(`   âš ï¸ ElevenLabs ì‹¤íŒ¨, OpenAIë¡œ í´ë°±: ${err.message}`);
          audioBuffer = await generateWithOpenAI(tutor.text, tutor.voice);
        }
      } else {
        audioBuffer = await generateWithOpenAI(tutor.text, tutor.voice);
      }

      const outputPath = path.join(OUTPUT_DIR, `${tutor.name}-greeting.mp3`);
      fs.writeFileSync(outputPath, audioBuffer);

      const sizeKB = (audioBuffer.length / 1024).toFixed(1);
      console.log(`   âœ… ì €ì¥ ì™„ë£Œ (${sizeKB} KB)\n`);
    } catch (err) {
      console.error(`   âŒ ì‹¤íŒ¨: ${err.message}\n`);
    }
  }

  console.log('ğŸ‰ ì™„ë£Œ! public/audio/greetings/ ì—ì„œ í™•ì¸í•˜ì„¸ìš”.');
}

main();
